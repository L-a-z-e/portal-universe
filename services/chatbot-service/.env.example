# === AI Provider ===
# LLM Provider: openai | anthropic | google | ollama
AI_PROVIDER=ollama
AI_MODEL=llama3
AI_API_KEY=

# === Embedding Provider ===
# Provider: openai | sentence-transformers | ollama
EMBEDDING_PROVIDER=ollama
EMBEDDING_MODEL=nomic-embed-text
EMBEDDING_API_KEY=  # AI_API_KEY와 다를 경우

# Ollama (local)
OLLAMA_BASE_URL=http://localhost:11434

# === Vector DB ===
VECTOR_DB_TYPE=chroma  # chroma | elasticsearch
CHROMA_PERSIST_DIR=./data/chroma
# Elasticsearch (기존 인프라 활용 시)
# ES_URL=http://localhost:9200

# === Redis (대화 이력) ===
REDIS_URL=redis://localhost:6379/1

# === Service ===
SERVICE_PORT=8086
LOG_LEVEL=INFO
DOCUMENTS_DIR=./documents

# === CORS ===
# local: 기본값 사용 (CORS_ENABLED=true, CORS_ORIGINS=["http://localhost:30000"])
# docker/k8s: Gateway가 CORS 처리하므로 CORS_ENABLED=false
# 주의: list 타입 필드는 JSON 배열 형식 필수 (pydantic-settings v2)
CORS_ENABLED=true
CORS_ORIGINS=["http://localhost:30000"]

# === RAG ===
RAG_CHUNK_SIZE=1000
RAG_CHUNK_OVERLAP=200
RAG_TOP_K=5
RAG_SCORE_THRESHOLD=0.7
