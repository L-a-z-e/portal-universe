# ⚠️ 개발 환경 전용 (Development Only)
# 모든 포트가 호스트에 바인딩되어 있습니다.
# 프로덕션에서는 필요한 포트만 노출하세요.
services:
  # ========================================
  # PostgreSQL (auth, shopping, seller, settlement, prism, drive)
  # ========================================
  postgresql:
    image: postgres:18-alpine
    container_name: postgresql
    mem_limit: 512m
    memswap_limit: 512m
    cpus: 0.5
    pids_limit: 128
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    ports:
      - "127.0.0.1:5432:5432"
    volumes:
      - postgresql-data:/var/lib/postgresql/data
      - ./infrastructure/postgresql/init-prism.sql:/docker-entrypoint-initdb.d/01-init-prism.sql
      - ./infrastructure/postgresql/init-drive.sql:/docker-entrypoint-initdb.d/02-init-drive.sql
      - ./infrastructure/postgresql/init-services.sql:/docker-entrypoint-initdb.d/03-init-services.sql
    env_file:
      - .env.docker
    networks:
      - portal-universe-net
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U $$POSTGRES_USER -d $$POSTGRES_DB"]
      interval: 10s
      timeout: 5s
      retries: 5

  # MySQL (notification-service 전용)
  mysql-db:
    image: mysql:8.0
    container_name: mysql-db
    mem_limit: 512m
    memswap_limit: 512m
    cpus: 0.5
    pids_limit: 128
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    ports:
      - "127.0.0.1:3307:3306"
    volumes:
      - mysql-data:/var/lib/mysql
      - ./infrastructure/mysql/init.sql:/docker-entrypoint-initdb.d/init.sql
    env_file:
      - .env.docker
    networks:
      - portal-universe-net
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost"]
      interval: 10s
      timeout: 5s
      retries: 5

  mongodb:
    image: mongo:8.0
    container_name: mongodb
    mem_limit: 512m
    memswap_limit: 512m
    cpus: 1.0
    pids_limit: 256
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    ports:
      - "127.0.0.1:27017:27017"
    volumes:
      - mongo-data:/data/db
    env_file:
      - .env.docker
    networks:
      - portal-universe-net

  redis:
    image: redis:7.4-alpine
    container_name: redis
    mem_limit: 256m
    memswap_limit: 256m
    cpus: 0.5
    pids_limit: 128
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    ports:
      - "127.0.0.1:6379:6379"
    command: redis-server --appendonly yes
    volumes:
      - redis-data:/data
    networks:
      - portal-universe-net
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  elasticsearch:
    build:
      context: ./infrastructure/elasticsearch
      dockerfile: Dockerfile
    container_name: elasticsearch
    mem_limit: 2g
    memswap_limit: 2g
    cpus: 2.0
    pids_limit: 512
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "5"
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - http.compression=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ports:
      - "127.0.0.1:9200:9200"
    volumes:
      - es-data:/usr/share/elasticsearch/data
    networks:
      - portal-universe-net
    healthcheck:
      test: ["CMD-SHELL", "curl -s http://localhost:9200/_cluster/health | grep -q 'green\\|yellow'"]
      interval: 30s
      timeout: 10s
      retries: 5

  kibana:
    image: docker.elastic.co/kibana/kibana:8.18.5
    container_name: kibana
    mem_limit: 1g
    memswap_limit: 1g
    cpus: 1.5
    pids_limit: 256
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    ports:
      - "127.0.0.1:5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    depends_on:
      elasticsearch:
        condition: service_healthy
    networks:
      - portal-universe-net

  kafka:
    image: apache/kafka:4.1.1
    container_name: kafka
    mem_limit: 1536m
    memswap_limit: 1536m
    cpus: 2.0
    pids_limit: 512
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "5"
    ports:
      - "127.0.0.1:9092:9092"
      - "127.0.0.1:29092:29092"
      - "127.0.0.1:9093:9093"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENERS: PLAINTEXT://:29092,PLAINTEXT_HOST://:9092,CONTROLLER://:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092,CONTROLLER://kafka:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT,CONTROLLER:PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_LOG_DIRS: /tmp/kraft-kafka-logs
      KAFKA_CLUSTER_ID: "5L6g3nShT-eMCtK--X86sw"
    networks:
      - portal-universe-net
    healthcheck:
      test: ["CMD-SHELL", "/opt/kafka/bin/kafka-broker-api-versions.sh --bootstrap-server localhost:9092 || exit 1"]
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 30s

  # ========================================
  # Schema Registry + AKHQ (Avro/Kafka Management)
  # ========================================
  schema-registry:
    image: confluentinc/cp-schema-registry:8.1.1
    hostname: schema-registry
    container_name: schema-registry
    mem_limit: 512m
    memswap_limit: 512m
    cpus: 0.5
    pids_limit: 128
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    ports:
      - "127.0.0.1:18081:8081"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: kafka:29092
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
      SCHEMA_REGISTRY_SCHEMA_COMPATIBILITY_LEVEL: BACKWARD_TRANSITIVE
    depends_on:
      kafka:
        condition: service_healthy
    networks:
      - portal-universe-net
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8081/subjects || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5

  akhq:
    image: tchiotludo/akhq:0.26.0
    container_name: akhq
    mem_limit: 512m
    memswap_limit: 512m
    cpus: 0.5
    pids_limit: 128
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    ports:
      - "127.0.0.1:9000:8080"
    environment:
      AKHQ_CONFIGURATION: |
        akhq:
          connections:
            portal:
              properties:
                bootstrap.servers: kafka:29092
              schema-registry:
                url: http://schema-registry:8081
    depends_on:
      kafka:
        condition: service_healthy
      schema-registry:
        condition: service_healthy
    networks:
      - portal-universe-net

  # ========================================
  # Application Services
  # ========================================
  api-gateway:
    build:
      context: .
      dockerfile: ./services/api-gateway/Dockerfile
    container_name: api-gateway
    mem_limit: 768m
    memswap_limit: 768m
    cpus: 1.0
    pids_limit: 256
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    ports:
      - "127.0.0.1:8080:8080"
    environment:
      - SPRING_PROFILES_ACTIVE=docker
      - SPRING_CLOUD_GATEWAY_SERVER_WEBFLUX_TRUSTEDPROXIES=[0.0.0.0/0]
      - SPRING_SECURITY_OAUTH2_RESOURCESERVER_JWT_ISSUER_URI=https://portal-universe:30000/auth-service
      - APP_FRONTEND_BASE_URL=http://portal-universe:30000
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8080/actuator/health" ]
      interval: 10s
      timeout: 5s
      retries: 5
    depends_on:
      auth-service:
        condition: service_healthy
    networks:
      - portal-universe-net

  auth-service:
    build:
      context: .
      dockerfile: ./services/auth-service/Dockerfile
    container_name: auth-service
    mem_limit: 768m
    memswap_limit: 768m
    cpus: 1.0
    pids_limit: 256
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    ports:
      - "127.0.0.1:8081:8081"
    env_file:
      - path: ./services/auth-service/.env.docker
        required: true
    environment:
      - SPRING_PROFILES_ACTIVE=docker
      - SPRING_SECURITY_OAUTH2_AUTHORIZATIONSERVER_ISSUER=https://portal-universe:30000/auth-service
      - SERVER_FORWARD_HEADERS_STRATEGY=framework
      - SERVER_USE_FORWARD_HEADERS=true
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - DB_USER=laze
      - DB_PASSWORD=Laze2026!
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081/actuator/health"]
      interval: 10s
      timeout: 5s
      retries: 5
    depends_on:
      postgresql:
        condition: service_healthy
      kafka:
        condition: service_started
      redis:
        condition: service_healthy
    networks:
      - portal-universe-net

  blog-service:
    build:
      context: .
      dockerfile: ./services/blog-service/Dockerfile
    container_name: blog-service
    mem_limit: 768m
    memswap_limit: 768m
    cpus: 1.0
    pids_limit: 256
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    ports:
      - "127.0.0.1:8082:8082"
    environment:
      - SPRING_PROFILES_ACTIVE=docker
      - MONGO_USER=laze
      - MONGO_PASSWORD=Laze2026!
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8082/actuator/health" ]
      interval: 10s
      timeout: 5s
      retries: 5
    depends_on:
      api-gateway:
        condition: service_healthy
      mongodb:
        condition: service_started
    networks:
      - portal-universe-net

  shopping-service:
    build:
      context: .
      dockerfile: ./services/shopping-service/Dockerfile
    container_name: shopping-service
    mem_limit: 768m
    memswap_limit: 768m
    cpus: 1.0
    pids_limit: 256
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    ports:
      - "127.0.0.1:8083:8083"
    environment:
      - SPRING_PROFILES_ACTIVE=docker
      - DB_USER=laze
      - DB_PASSWORD=Laze2026!
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8083/actuator/health" ]
      interval: 10s
      timeout: 5s
      retries: 5
    depends_on:
      api-gateway:
        condition: service_healthy
      postgresql:
        condition: service_healthy
      kafka:
        condition: service_started
      redis:
        condition: service_started
      elasticsearch:
        condition: service_healthy
    networks:
      - portal-universe-net

  notification-service:
    build:
      context: .
      dockerfile: ./services/notification-service/Dockerfile
    container_name: notification-service
    mem_limit: 768m
    memswap_limit: 768m
    cpus: 1.0
    pids_limit: 256
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    ports:
      - "127.0.0.1:8084:8084"
    environment:
      - SPRING_PROFILES_ACTIVE=docker
      - DB_USER=laze
      - DB_PASSWORD=Laze2026!
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8084/actuator/health" ]
      interval: 10s
      timeout: 5s
      retries: 5
    depends_on:
      api-gateway:
        condition: service_healthy
      kafka:
        condition: service_started
      mysql-db:
        condition: service_started
      redis:
        condition: service_started
    networks:
      - portal-universe-net

  portal-shell:
    build:
      context: ./frontend
      dockerfile: portal-shell/Dockerfile
      args:
        BUILD_MODE: docker
    container_name: portal-shell
    mem_limit: 128m
    memswap_limit: 128m
    cpus: 0.25
    pids_limit: 64
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    ports:
      - "127.0.0.1:30000:8443"
    volumes:
      - ./certs:/etc/nginx/certs:ro
    depends_on:
      api-gateway:
        condition: service_healthy
    networks:
      - portal-universe-net

  blog-frontend:
    build:
      context: ./frontend
      dockerfile: blog-frontend/Dockerfile
      args:
        BUILD_MODE: docker
    container_name: blog-frontend
    mem_limit: 128m
    memswap_limit: 128m
    cpus: 0.25
    pids_limit: 64
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    ports:
      - "127.0.0.1:30001:8080"
    depends_on:
      portal-shell:
        condition: service_started
    networks:
      - portal-universe-net

  shopping-frontend:
    build:
      context: ./frontend
      dockerfile: shopping-frontend/Dockerfile
      args:
        BUILD_MODE: docker
    container_name: shopping-frontend
    mem_limit: 128m
    memswap_limit: 128m
    cpus: 0.25
    pids_limit: 64
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    ports:
      - "127.0.0.1:30002:8080"
    depends_on:
      portal-shell:
        condition: service_started
    networks:
      - portal-universe-net

  # ========================================
  # Prism Service (AI Orchestration)
  # ========================================
  prism-service:
    build:
      context: ./services/prism-service
      dockerfile: Dockerfile
    container_name: prism-service
    mem_limit: 512m
    memswap_limit: 512m
    cpus: 1.0
    pids_limit: 256
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    ports:
      - "127.0.0.1:8085:8085"
    env_file:
      - ./services/prism-service/.env.docker
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8085/api/v1/health"]
      interval: 10s
      timeout: 5s
      retries: 5
    depends_on:
      postgresql:
        condition: service_healthy
      api-gateway:
        condition: service_healthy
      kafka:
        condition: service_started
      redis:
        condition: service_healthy
    networks:
      - portal-universe-net

  prism-frontend:
    build:
      context: ./frontend
      dockerfile: prism-frontend/Dockerfile
      args:
        BUILD_MODE: docker
    container_name: prism-frontend
    mem_limit: 128m
    memswap_limit: 128m
    cpus: 0.25
    pids_limit: 64
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    ports:
      - "127.0.0.1:30003:8080"
    depends_on:
      portal-shell:
        condition: service_started
    networks:
      - portal-universe-net

  admin-frontend:
    build:
      context: ./frontend
      dockerfile: admin-frontend/Dockerfile
      args:
        BUILD_MODE: docker
    container_name: admin-frontend
    mem_limit: 128m
    memswap_limit: 128m
    cpus: 0.25
    pids_limit: 64
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    ports:
      - "127.0.0.1:30004:8080"
    depends_on:
      portal-shell:
        condition: service_started
    networks:
      - portal-universe-net

  # ========================================
  # Chatbot Service (Python/FastAPI)
  # ========================================
  chatbot-service:
    build:
      context: ./services/chatbot-service
      dockerfile: Dockerfile
    container_name: chatbot-service
    mem_limit: 512m
    memswap_limit: 512m
    cpus: 1.0
    pids_limit: 256
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    ports:
      - "127.0.0.1:8086:8086"
    environment:
      - AI_PROVIDER=${AI_PROVIDER:-ollama}
      - AI_MODEL=${AI_MODEL:-llama3}
      - AI_API_KEY=${AI_API_KEY:-}
      - EMBEDDING_PROVIDER=${EMBEDDING_PROVIDER:-ollama}
      - EMBEDDING_MODEL=${EMBEDDING_MODEL:-nomic-embed-text}
      - OLLAMA_BASE_URL=http://ollama:11434
      - REDIS_URL=redis://redis:6379/1
      - CORS_ENABLED=false
      - CHROMA_PERSIST_DIR=/app/data/chroma
      - DOCUMENTS_DIR=/app/documents
      - SERVICE_PORT=8086
      - LOG_LEVEL=INFO
      - TRACING_ENABLED=true
      - ZIPKIN_ENDPOINT=http://zipkin:9411/api/v2/spans
    volumes:
      - chatbot-data:/app/data
      - chatbot-docs:/app/documents
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - portal-universe-net
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8086/api/v1/chat/health')"]
      interval: 10s
      timeout: 5s
      retries: 5

  # ========================================
  # Monitoring Stack
  # ========================================
  prometheus:
    image: prom/prometheus:v2.53.5
    container_name: prometheus
    mem_limit: 512m
    memswap_limit: 512m
    cpus: 1.0
    pids_limit: 128
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    volumes:
      - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./monitoring/prometheus/rules:/etc/prometheus/rules
      - prometheus-data:/prometheus
    ports:
      - "127.0.0.1:9090:9090"
    networks:
      - portal-universe-net
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
      - '--web.enable-remote-write-receiver'

  alertmanager:
    image: prom/alertmanager:v0.28.1
    container_name: alertmanager
    mem_limit: 128m
    memswap_limit: 128m
    cpus: 0.25
    pids_limit: 64
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    volumes:
      - ./monitoring/alertmanager/alertmanager.yml:/etc/alertmanager/alertmanager.yml
      - ./monitoring/alertmanager/templates:/etc/alertmanager/templates
      - alertmanager-data:/alertmanager
    ports:
      - "127.0.0.1:9094:9093"
    networks:
      - portal-universe-net
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--storage.path=/alertmanager'
    restart: unless-stopped

  grafana:
    image: grafana/grafana-oss:11.4.0
    container_name: grafana
    mem_limit: 512m
    memswap_limit: 512m
    cpus: 1.0
    pids_limit: 256
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    env_file:
      - .env.docker
    environment:
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_SERVER_ROOT_URL=http://localhost:3000
      - GF_INSTALL_PLUGINS=grafana-piechart-panel
    volumes:
      - grafana-data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning
    ports:
      - "127.0.0.1:3000:3000"
    networks:
      - portal-universe-net
    depends_on:
      - prometheus
      - loki

  loki:
    image: grafana/loki:2.9.0
    container_name: loki
    mem_limit: 256m
    memswap_limit: 256m
    cpus: 0.5
    pids_limit: 128
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    volumes:
      - ./monitoring/loki/loki-config.yml:/etc/loki/local-config.yaml
      - loki-data:/loki
    ports:
      - "127.0.0.1:3100:3100"
    networks:
      - portal-universe-net
    command: -config.file=/etc/loki/local-config.yaml
    restart: unless-stopped

  promtail:
    image: grafana/promtail:2.9.0
    container_name: promtail
    mem_limit: 256m
    memswap_limit: 256m
    cpus: 0.5
    pids_limit: 128
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    volumes:
      - ./monitoring/promtail/promtail-config.yml:/etc/promtail/config.yml
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock
    networks:
      - portal-universe-net
    command: -config.file=/etc/promtail/config.yml
    depends_on:
      - loki
    restart: unless-stopped

  zipkin:
    image: openzipkin/zipkin:3.5.1
    container_name: zipkin
    mem_limit: 512m
    memswap_limit: 512m
    cpus: 1.0
    pids_limit: 256
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    ports:
      - "127.0.0.1:9411:9411"
    environment:
      - STORAGE_TYPE=elasticsearch
      - ES_HOSTS=http://elasticsearch:9200
      - ES_INDEX=zipkin
      - ES_INDEX_REPLICAS=0
      - ES_INDEX_SHARDS=1
    depends_on:
      elasticsearch:
        condition: service_healthy
    networks:
      - portal-universe-net

  # ========================================
  # Exporters (Performance Monitoring)
  # ========================================
  cadvisor:
    image: gcr.io/cadvisor/cadvisor:v0.49.1
    container_name: cadvisor
    command:
      - '--store_container_labels=true'
      - '--whitelisted_container_labels=com.docker.compose.service'
    mem_limit: 256m
    memswap_limit: 256m
    cpus: 0.5
    pids_limit: 128
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    ports:
      - "127.0.0.1:8888:8080"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
    networks:
      - portal-universe-net
    restart: unless-stopped

  mysql-exporter:
    image: prom/mysqld-exporter:v0.15.0
    container_name: mysql-exporter
    mem_limit: 128m
    memswap_limit: 128m
    cpus: 0.25
    pids_limit: 64
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    ports:
      - "127.0.0.1:9104:9104"
    volumes:
      - ./infrastructure/mysql/exporter.my.cnf:/.my.cnf:ro
    depends_on:
      mysql-db:
        condition: service_healthy
    networks:
      - portal-universe-net
    restart: unless-stopped

  redis-exporter:
    image: oliver006/redis_exporter:v1.66.0
    container_name: redis-exporter
    mem_limit: 128m
    memswap_limit: 128m
    cpus: 0.25
    pids_limit: 64
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    ports:
      - "127.0.0.1:9121:9121"
    environment:
      REDIS_ADDR: "redis://redis:6379"
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - portal-universe-net
    restart: unless-stopped

  kafka-exporter:
    image: danielqsj/kafka-exporter:v1.8.0
    container_name: kafka-exporter
    mem_limit: 128m
    memswap_limit: 128m
    cpus: 0.25
    pids_limit: 64
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    ports:
      - "127.0.0.1:9308:9308"
    command:
      - "--kafka.server=kafka:29092"
      - "--topic.filter=.*"
      - "--group.filter=.*"
    depends_on:
      kafka:
        condition: service_healthy
    networks:
      - portal-universe-net
    restart: unless-stopped

  localstack:
    image: localstack/localstack:4.3.0
    container_name: localstack
    mem_limit: 512m
    memswap_limit: 512m
    cpus: 1.0
    pids_limit: 256
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    ports:
      - "127.0.0.1:4566:4566"
    environment:
      - SERVICES=s3
      - AWS_DEFAULT_REGION=ap-northeast-2
      - PERSISTENCE=1
    volumes:
      - ./localstack_data:/var/lib/localstack
      - ./localstack-init:/etc/localstack/init/ready.d
    networks:
      - portal-universe-net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:4566/_localstack/health"]
      interval: 10s
      timeout: 5s
      retries: 5

  dozzle:
    image: amir20/dozzle:v8.14.5
    mem_limit: 128m
    memswap_limit: 128m
    cpus: 0.25
    pids_limit: 64
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    ports:
      - "127.0.0.1:9999:8080"
    networks:
      - portal-universe-net

volumes:
  postgresql-data:
  mysql-data:
  mongo-data:
  redis-data:
  es-data:
  prometheus-data:
  alertmanager-data:
  grafana-data:
  loki-data:
  localstack-data:
  chatbot-data:
  chatbot-docs:

networks:
  portal-universe-net:
